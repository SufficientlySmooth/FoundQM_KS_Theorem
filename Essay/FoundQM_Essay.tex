\documentclass[11pt, a4paper]{article}
\usepackage[
  height=9in,      % height of the text block
  width=7in,       % width of the text block
  top=78pt,        % distance of the text block from the top of the page
  %headheight=48pt, % height for the header block
 % headsep=12pt,    % distance from the header block to the text block
  heightrounded,   % ensure an integer number of lines  
  left=2.1cm, right=2.1cm, top=1.5cm, bottom=2cm         % show the values of the parameters in the log file
]{geometry}
\usepackage{setspace}
\usepackage{lipsum} 
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{lastpage}

\titleformat{\section}
  {\normalfont\sffamily\Large\bfseries}
  {\thesection}{1em}{}

\makeatletter
\newcommand{\MSonehalfspacing}{%
  \setstretch{1.44}%  default
  \ifcase \@ptsize \relax % 10pt
    \setstretch {1.448}%
  \or % 11pt
    \setstretch {1.399}%
  \or % 12pt
    \setstretch {1.433}%
  \fi
}
\newcommand{\MSdoublespacing}{%
  \setstretch {1.92}%  default
  \ifcase \@ptsize \relax % 10pt
    \setstretch {1.936}%
  \or % 11pt
    \setstretch {1.866}%
  \or % 12pt
    \setstretch {1.902}%
  \fi
}
\makeatother
%\MSonehalfspacing
\usepackage[colorlinks=false, hidelinks]{hyperref}
\usepackage[english]{babel}   
\usepackage[utf8]{inputenc} 
\usepackage{setspace}
\usepackage{enumitem}
\usepackage{graphicx}

%\setlength{\parskip}{10pt}
\newcommand\sbullet[1][.5]{\mathbin{\vcenter{\hbox{\scalebox{#1}{$\bullet$}}}}}

\usepackage{lmodern}
\usepackage[scale=2]{ccicons}
\usepackage[backend=bibtex,style=alphabetic,sorting=none,style=numeric]{biblatex} 
\usepackage{stmaryrd}%for lightning
\usepackage{amsmath,amssymb}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{datetime}

\DeclareMathOperator*{\SumInt}{%
\mathchoice%
  {\ooalign{$\displaystyle\sum$\cr\hidewidth$\displaystyle\int$\hidewidth\cr}}
  {\ooalign{\raisebox{.14\height}{\scalebox{.7}{$\textstyle\sum$}}\cr\hidewidth$\textstyle\int$\hidewidth\cr}}
  {\ooalign{\raisebox{.2\height}{\scalebox{.6}{$\scriptstyle\sum$}}\cr$\scriptstyle\int$\cr}}
  {\ooalign{\raisebox{.2\height}{\scalebox{.6}{$\scriptstyle\sum$}}\cr$\scriptstyle\int$\cr}}
}


\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}
\newcommand{\R}{\mathbb{R}}
\addbibresource{bib_thesis.bib}


\begin{document}

\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\fancyhf{}
\fancyhf[cf]{Page \thepage\ of \pageref{LastPage}}

\section*{On the necessity for continuous reversible transformations in Lucien Hardy's five axioms for quantum theory}
\vspace{-0.3cm}
\textsf{by Jan-Philipp Christ (LMU Munich). Date of submission: August 11, 2023}\par
\vspace{4pt}
Lucien Hardy's five axioms for quantum theory are a remarkable attempt to derive the formalism of quantum mechanics from a few intuitive and reasonable principles \cite{hardy2001quantum}. These axioms have been subject to avid debate since their publication around 20 years ago. In particular, there have been discussions whether a different or even more minimal choice of axioms exists \cite{Schack_2003, Masanes_2011} and about the 'reasonableness' of the axioms \cite{DARRIGOL}.\\
One of the axioms, axiom 5, states that there exist continuous reversible transformations between pure states. This axiom is crucial for ruling out classical probability theory and obtaining quantum theory instead, and seems to stand out from the other axioms, as it is the one that has not been replaced in alternative formulations of the axioms, such as \cite{Schack_2003, Masanes_2011}. However, it is also the most debatable of the five axioms, as it seems to rely on some mathematical assumptions that are, at least as set forth in his original paper, not clearly and sufficiently motivated by physical considerations.\par
To argue for the 'reasonableness' and the motivation of the fifth axiom is the goal of this essay. It is structured as follows: We will first briefly summarize Hardy's axioms, how he builds quantum theory upon them and how \emph{he} motivates his axioms. 
%We will then more closely examine the axioms and discuss in which sense they are well or naturally motivated. 
We will then in particular focus on his fifth axiom and try to argue whether it is indeed 'natural' and 'resonable' by taking into account both physical and information-theoretic considerations. \par
\vspace{8pt}
The setup Hardy introduces is the following: An experimenter has a preparation device, a transformation device, and a measurement device. The preparation device yields a \emph{state}, which is "(that thing represented by) any mathematical object that can be used to determine the probability associated with the outcomes of any measurement that may be performed on a system prepared by the given preparation" \cite{hardy2001quantum}. The preparation can be thought of as the set of all interactions of, say, a particle with its environment. If exactly the same preparation is repeated, it is assumed that it will produce the same state. Note that this does not imply that the preparation is independent of the context in which it is performed, because we can include the context of the preparation, e.g. where the preparation device is located, as a property of the preparation device itself.\\
Hardy further defines the \emph{dimension} $N$, equal to the maximum number of states distinguishable in a single measurement, and the \emph{number of degrees of freedom} $K$, equal to the minimum number of measurements to specify the state. Indices for either of these numbers indicate the system they are referring to. \\
The axioms read in their original formulation:
\begin{itemize}
\setlength{\itemindent}{3em}
\item[\textbf{Axiom 1}] (Probabilities) \emph{Relative frequencies (measured by taking the proportion of times a particular outcome is observed) tend to the same value (which we call the probability) for any case where a given measurement is performed on an ensemble of $n$ systems prepared by some given preparation in the limit as $n$ becomes infinite.}
\item[\textbf{Axiom 2}] (Simplicity) \emph{$K$ is determined by a function of $N$ (i.e. $K = K(N)$)  where $N=1,2,\ldots$ and where, for any given $N$, $K$ takes the minimum value consistent with the axioms.}
\item[\textbf{Axiom 3}] (Subspaces) \emph{A system whose state is constrained to belong to an $M$ dimensional subspace behaves like a system of dimension $M$.}
\item[\textbf{Axiom 4}] (Composite Systems) \emph{A composite system consisting of two subsystems A and B having dimension $N_A$ and $N_B$ respectively, and number of degrees of freedom $K_A$ and $K_B$ respectively, has dimension $N = N_AN_B$ and number of degrees of freedom $K = K_AK_B$.}
\item[\textbf{Axiom 5}] (Continuity) \emph{There exists a continuous reversible transformation on a system between any two pure states of the system.}
\end{itemize}
A few remarks are in order: First, most details of Hardy's mathematical proofs do not heavily rely on the rather experimentalist notion of probability introduced here. It is also possible to work within a Bayesian framework, where probabilities are seen as degrees of belief, with only minor adjustments to Hardy's line of reasoning \cite{Schack_2003}. Furthermore, the simplicity axiom turns out to be unnecessary, as Darrigol points out \cite{DARRIGOL}, and the composite systems axiom can be relaxed by not requiring $K = K_AK_B$, which is already implied in $N = N_AN_B$, as Hardy shows in his original work \cite[Sect. 6.15]{hardy2001quantum}.\\
Before defining pure states, as referenced in the fifth axiom, one should convince oneself that the definition of a state combined with the notion of the degree of freedom implies that $K$ appropriately chosen measurements are sufficient (and necessary) to define the state. The corresponding probabilities (and thus the state) will represented by a column vector $\mathbf p$. The mixture, i.e. convex combination, of two such states is still a admissible state because it has definite values for the probabilities and the relation between states and probability vectors is one-to-one. Hence, the set of all such probability vectors is convex. The pure states are defined as the non-zero extremal points of this convex set, i.e. those points that cannot be expressed as a convex combination of any other two states. Intuitively, the name 'pure' is clear: Such states cannot be written as a mixture of two other states. \par
\vspace{8pt}
We will go on to outline how Hardy derives important features of quantum theory from the five axioms introduced here. Mathematical details will be skimmed over, but we encourage the reader to work through the details in \cite{DARRIGOL} or \cite{hardy2001quantum}, for which only very elementary linear algebra is required. \\
Hardy looks at a system of dimension $N+1$. By considering a $N$ dimensional subsystem and its one dimensional complement, he argues that $K(N+1)\geq K(N)+1$. Moreover, the axiom 4 about composite systems implies that $K(N)$ is completely multiplicative, i.e. $K(N_A N_B)=K(N_A)K(N_B)$. It can be proven that a function with these properties can be written in the form $K(N)=N^\alpha, \alpha\in\R$. The restriction that $K$ is an integer now requires $r\defeq\alpha=1,2,\ldots$, and the simplicity axiom makes us choose the minimal value for $r$ which is still compatible with the other axioms.\\
Hardy proceeds by introducing $K$ probability vectors $\left\{\mathbf p_k\right\}_{k=1,\ldots,K}$ chosen such that they uniquely specify the state of the system and also $K$ \emph{fiducial measurements} which can be identified with and represented by measurement vectors $\left\{\mathbf r_n\right\}_{n=1,\ldots,K}$.\\
It can be shown that the measurement vectors $\mathbf r^M$ are related to measurement probability vectors by a linear transformation represented by a real-valued matrix $D$. Conversely, state probability vectors can be represented by $\mathbf r$-type vectors, i.e. $\mathbf p^S=D\mathbf r^S$ and $\mathbf p^M=D^T\mathbf r^M$. Here, the superscripts $M$ and $S$ indicate that a vector refers to a measurement or state, respectively. Then the measurement probability is $p_{\mathrm{meas}}=\mathbf p^M\cdot \mathbf r^S=(\mathbf r^M)^TD\mathbf r^S$.\par
On this basis, Hardy starts a proof by contradiction by assuming $K=N$, thus ruling out the case $r=1$. He does this by considering $N$ fiducial states which are also basis states, implying that $D$ is equal to the identity matrix. However, it can be shown that this implies that the squares of the components of a fiducial vector $\mathbf p$ sum to 1. But $\mathbf p$ must also be both normalized, i.e. its components must sum to 1.This means that all but one component must be one, as in classical probability theory. But classical probability theory is incompatible with continuity axiom 5, because discrete fiducial vectors (which are also pure) cannot be connected by continuous transformations. \par
So we must have $r>1$, and the simplicity axiom then requires $r=2$, which does not contradict any of the other axioms. Hardy then goes on to show that the $N=2$ case corresponds to the Bloch sphere. For general $N$ quantum theory can be obtained using the $N=2$ case.  He also obtains the trace formula for calculating probabilities of measurements represented by some operator $\hat A$ and systems represented by a density matrix $\hat\rho$. Furthermore, he shows that the tensor product offers the right mathematical structure to describe composite systems (axiom 4 already fixes the 'right' dimension of the composite system) and that the trace of the density matrix needs to be invariant under all physically feasable transformations, thus restricting the number of set of all allowed transformations. Again, for the mathematical details we refer to Hardy's original paper, especially to Section 8.7 ff. For the purposes of this essay, it is only necessary to know where the various axioms come into play in recovering quantum theory from them, since the following discussions will be rather conceptual in nature.\par
\vspace{8pt}
It is interesting that Hardy's axioms, which are not defined in a mathematically rigorous way, give rise to rich mathematics, including the Hilbert state structure of quantum mechanics. In fact, Hardy himself stated as the goal of his axioms to show that it would have been \emph{possible} for a 19th century ancestor of Schrödinger or the like to arrive at a quantum theory from reasonable assumptions alone, thus showing the inevitability of quantum theory. To prove this point, the simplicity with which the axioms can be worded is thus quite intentional, as is the 'reasonableness' of the axioms.\par
Hardy does not give a clear motivation for his first axiom, suggesting that his choice of definition of probabilities was made for its conceptual simplicity. But he does point out that other notions of probability should lead to the same conclusions. And indeed, only a year after Hardy's publication, it was shown that the axioms also work in a Bayesian framework \cite{Schack_2003}, thus eliminating the criticism that Hardy's insufficient distinction between measured frequencies and probabilities is problematic.\par
The second axiom is not fully motivated. Hardy appeals to "a certain constancy in nature such that $K$ is a function of $N$" but does not argue why $K$ should take the smallest value consistent with the axioms, even though he seems to be arguing akin to the spirit of Ockham's Razor, not requiring 'unnecessary' complexity from theories describing nature.\par
The third axiom is motivated by the fact that "we expect a probability theory pertaining to $M$ propositions to be independent of whether these propositions are a subset or some larger set or not". We can also motivate it from a information-theoretic perspective by looking at an one-dimensional non-interacting spin-chain: If a $M$ dimensional subspace of that system, i.e. $M$ spins with the information content of 1 Bit each, would behave like a system of dimension $M^\prime >M$, it would be possible to store more than $M$ bit in that system. This, however, cannot be done because all other spins, i.e. all other bits, are fixed and cannot store any information. If, on the other hand, a $M$ dimensional subspace of a length $M+N$ spin-chain composed of two non-interacting subsystems would behave like a system of dimension $M^\prime < M$, the total information that could be stored would be $M^\prime+N$ bits which is smaller than the total information capacity of the system ($M+N$ bits).\par
For the fourth axiom Hardy notes that "if subsystems A and B have $N_A$ and $N_B$ distinguishable states, then there must certainly exist $N_A$ and $N_B$ distinguishable states for the whole system". So the actual assumption of the axiom is not $N=N_AN_B$ but $N\leq N_AN_B$, which can be thought of as allowing only the minimal number of entangled states between the two subsystems, which is again reminiscent of Ockham's razor. \par
Remarkably, the fifth axiom, the continuity axiom, is the axiom that sets classical probability theory apart from quantum theory but also seems to be the least motivated amongst the five axioms. Hardy remarks "we expect to be able to transform the state of a system from any pure state to any other pure state [...] in a way that does not extract information about the state and so we expect this can be done by a reversible transformation". This can be considered to be a good motivation for reversibility. It is his argument for the continuity of the transformation to "expect any such transformation to be continuous since there are generally no discontinuities in physics" that can and should be questioned. It is indeed the case that in our macroscopic world usually no discontinuities arise, even if we try to provoke them. Here are two examples that a 19th century physicist might have come up with: When trying to modulate voltage along a square wave, the edges will always be smoothed out; when trying  expand a gas very rapidly, you will find that the pressure exerted on the outer walls of the vessel used does change rapidly, but up on closer inspection there will be no jumps or the like. But looking at (discrete!) atomic spectra, for example, it is not clear a priori that the underlying processes are continuous. Since the point of quantum theory is to describe the structure underlying these very processes, it does not seem natural to require these transformations to be continuous.\par
In what follows, we will argue that it is nevertheless reasonable to assume and require that the transformations between pure states are continuous. We will argue in four ways: First, we will use a correspondence argument involving magnetically ordered systems. Second, we will exploit the fact that pure states can be characterized by their entropy. Third, we will use the continuity of time evolution to argue for the continuity of more general transformations. Finally, as an outlook, we will speculate whether perhaps the requirement of causal order already implies continuity.\par
\vspace{8pt}
This first argument is an argument by classical correspondence based on Darrigol \cite{DARRIGOL}. We expect classical to emerge from quantum behavior when a sufficiently large number of non-interacting copies of the same system in the same pure state is considered. Here we will consider spins in the $\mathbf u\in\R^3$ direction where each spin is in the $|+_{\mathbf u}\rangle$ state. Magnetic precession, a classically known phenomenon, allows us to transform the total angular momentum $N\hbar\mathbf u/2$ to any $N\hbar\mathbf u^\prime/2$ by applying an appropriately chosen magnetic field to the system. This precession happens continuously, and its end state requires each individual spin to be in the $|+_{\mathbf u^\prime}\rangle$ state. Similar arguments can be made for arbitrary spin states of the individual spins, thus making the possibility for continuous transformations between (any) two pure states plausible.\par
For our next argument we will make us of the fact that pure states have zero entropy $S(\mathbf p)\equiv-\mathbf p\cdot\mathrm{ln}\left(\mathbf p\right)$ (the logarithm is applied component-wise). This concept is independent of the von Neumann entropy and can be motivated from an information theoretic perspective or from statistical mechanics. Pure states, by definition, cannot be written as a mixture of any other states. Thus, for any measurement performed on pure states, our knowledge of the measurement result is maximal and our ignorance, which can be interpreted as entropy, is minimal. In general $S(\mathbf p)\geq 0$. Zero is indeed reached as a lower bound because clearly $S((1,0,\ldots,0)^T)=0$. Hence, all pure states have zero entropy. If, on the other hand, a state has zero entropy and it \emph{could} be written as the non trivial mixture of two pure states $\mathbf p_a,\mathbf p_b$, then by the convexity of $x\mapsto x\mathrm{ln}\left(x\right)$ $S(\lambda \mathbf p_a + (1-\lambda)\mathbf p_b)>\lambda S(\mathbf p_a)+(1-\lambda)S(\mathbf p_b)=\lambda\cdot 0 + (1-\lambda)\cdot 0=0$, contradicting the assumption. Hence, an alternative way to characterize the set of pure states is $\mathbf p$ pure $\iff S(\mathbf p)=0$. This equation defines a differentiable manifold of dimensionality $K-1$ on our set of state vectors. As such, it continuously connects all pure state vectors. It is not clear that all transformations on that manifold are physically admissible. But in combination with a correspondence argument like before we know that some transformations on that manifold can indeed be realized, thus very strongly suggesting that any two pure states are continuously connected by a reversible transformation.\par
For our third argument, 



%\nocite{*}
\printbibliography


\end{document}
